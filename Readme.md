I want to RUN a lite model on my 8GB RAM laptop
- used whisper.cpp (C++ version for faster inference)
- used pywhispercpp librbary to load 'tiny' model for ASR

